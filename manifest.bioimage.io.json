{
  "id": "bioimage.io",
  "name": "BioImage.IO",
  "tags": [],
  "logo": "\ud83e\udd92",
  "icon": "\ud83e\udd92",
  "splash_title": "Bioimage Model Zoo",
  "splash_subtitle": "Advanced AI models in one-click",
  "splash_feature_list": [
    "Integrate with Fiji, Ilastik, ImJoy",
    "Try model instantly with BioEngine",
    "Contribute your models via Github",
    "Link models to datasets and applications"
  ],
  "explore_button_text": "Start Exploring",
  "background_image": "static/img/zoo-background.svg",
  "resource_types": [
    "model",
    "application",
    "notebook",
    "dataset"
  ],
  "default_type": "model",
  "url_root": "https://raw.githubusercontent.com/bioimage-io/bioimage-io-models/master",
  "collections": [
    {
      "id": "ilastik",
      "name": "ilastik",
      "tags": [
        "ilastik"
      ],
      "logo": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/master/image/ilastik-fist-icon.png",
      "icon": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/master/image/ilastik-fist-icon.png",
      "splash_title": "ilastik",
      "splash_subtitle": "the interactive learning and segmentation toolkit",
      "splash_feature_list": null,
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "model",
        "application"
      ],
      "default_type": "model",
      "url_root": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/master"
    },
    {
      "id": "zero",
      "name": "ZeroCostDL4Mic",
      "version": "1.7.1",
      "tags": [
        "ZeroCostDL4Mic"
      ],
      "logo": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostLogo.png",
      "icon": "https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostLogo.png",
      "splash_title": "ZeroCostDL4Mic",
      "splash_subtitle": "A Google Colab based no-cost toolbox to explore Deep-Learning in Microscopy",
      "splash_feature_list": [],
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "model",
        "notebook",
        "dataset"
      ],
      "default_type": "notebook",
      "url_root": "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master"
    },
    {
      "id": "imjoy",
      "name": "ImJoy",
      "tags": [
        "imjoy"
      ],
      "logo": "https://imjoy.io/static/img/imjoy-icon.svg",
      "icon": "https://imjoy.io/static/img/imjoy-icon.svg",
      "splash_title": "ImJoy",
      "splash_subtitle": "Deep Learning Made Easy!",
      "splash_feature_list": [
        "Minimal and flexible plugin powered web application",
        "Server-less progressive web application with offline support",
        "Rich and interactive user interface powered by web technologies"
      ],
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "notebook",
        "application"
      ],
      "default_type": "application",
      "url_root": "https://raw.githubusercontent.com/imjoy-team/bioimage-io-models/master"
    },
    {
      "id": "hpa",
      "name": "HPA",
      "tags": [
        "hpa"
      ],
      "logo": "https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/hpa-logo.gif",
      "icon": "https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/hpa-logo.gif",
      "about_url": "https://www.proteinatlas.org/",
      "splash_title": "The Human Protein Atlas",
      "splash_subtitle": null,
      "splash_feature_list": [],
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "model",
        "application"
      ],
      "default_type": "model"
    },
    {
      "id": "fiji",
      "name": "Fiji",
      "tags": [
        "fiji"
      ],
      "logo": "https://fiji.sc/site/logo.png",
      "icon": "https://fiji.sc/site/logo.png",
      "splash_title": "Fiji",
      "splash_subtitle": "Fiji is just ImageJ",
      "splash_feature_list": [],
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "model",
        "notebook"
      ],
      "url_root": "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master"
    },
    {
      "id": "deepimagej",
      "name": "DeepImageJ",
      "tags": [
        "deepimagej"
      ],
      "logo": "https://raw.githubusercontent.com/deepimagej/models/master/logos/logo.png",
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "splash_title": "deepImageJ",
      "splash_subtitle": "A user-friendly plugin to run deep learning models in ImageJ",
      "splash_feature_list": null,
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "model",
        "notebook",
        "application"
      ],
      "url_root": "https://raw.githubusercontent.com/deepimagej/models/master"
    }
  ],
  "resources": [
    {
      "id": "fiji/Fiji",
      "name": "Fiji",
      "description": "Fiji is an image processing package \u2014 a \"batteries-included\" distribution of ImageJ, bundling many plugins which facilitate scientific image analysis.",
      "source": "https://fiji.sc/",
      "cite": {
        "text": "Schindelin, J., Arganda-Carreras, I., Frise, E. et al. Fiji: an open-source platform for biological-image analysis. Nat Methods 9, 676\u2013682 (2012).",
        "doi": "https://doi.org/10.1038/nmeth.2019"
      },
      "authors": [
        "Fiji community"
      ],
      "icon": "https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/Fiji-icon.png",
      "documentation": "https://fiji.sc/",
      "git_repo": "https://github.com/fiji/fiji,",
      "passive": true,
      "tags": [
        "fiji"
      ],
      "type": "application"
    },
    {
      "id": "deepimagej/deepimagej-beta",
      "type": "application",
      "name": "DeepImageJ Beta",
      "description": "DeepImageJ is a user-friendly plugin that enables the use of pre-trained deep learning models in ImageJ and Fiji.",
      "source": "https://deepimagej.github.io/deepimagej/beta_release.html",
      "cite": {
        "text": "G\u00f3mez-de-Mariscal, E., Garc\u00eda-L\u00f3pez-de-Haro, C., Donati, L., Unser, M., Mu\u00f1oz-Barrutia, A. and Sage, D. DeepImageJ: A user-friendly plugin to run deep learning models in ImageJ, BioRxiv, 2019",
        "doi": "https://doi.org/10.1101/799270"
      },
      "authors": [
        "DeepImageJ team"
      ],
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon-beta.png",
      "documentation": "https://deepimagej.github.io/deepimagej/index.html",
      "git_repo": "https://github.com/deepimagej/deepimagej-plugin",
      "tags": [
        "deepimagej-beta",
        "deepimagej"
      ]
    },
    {
      "id": "deepimagej/deepimagej",
      "type": "application",
      "name": "DeepImageJ",
      "description": "DeepImageJ is a user-friendly plugin that enables the use of pre-trained deep learning models in ImageJ and Fiji.",
      "source": "https://deepimagej.github.io/deepimagej/index.html",
      "cite": {
        "text": "G\u00f3mez-de-Mariscal, E., Garc\u00eda-L\u00f3pez-de-Haro, C., Donati, L., Unser, M., Mu\u00f1oz-Barrutia, A. and Sage, D. DeepImageJ: A user-friendly plugin to run deep learning models in ImageJ, BioRxiv, 2019",
        "doi": "https://doi.org/10.1101/799270"
      },
      "authors": [
        "DeepImageJ team"
      ],
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "documentation": "https://deepimagej.github.io/deepimagej/index.html",
      "git_repo": "https://github.com/deepimagej/deepimagej-plugin",
      "tags": [
        "deepimagej"
      ]
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_txred_super-resolution",
      "id": "deepimagej/WidefieldTxredSuperResolution",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_txred_super-resolution/model.yaml",
      "download_url": "https://zenodo.org/record/4290871/files/widefield_txred_superresolution.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Widefield Super-resolution (GAN - TxRed)",
      "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
          "doi": "https://doi.org/10.1038/s41592-018-0239-0"
        }
      ],
      "authors": [
        "Hongda Wang",
        "Yair Rivenson",
        "Aydogan Ozcan"
      ],
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "GAN",
        "Fluorescence microscopy",
        "deepimagej",
        "Super resolution"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_fitc_super-resolution",
      "id": "deepimagej/WidefieldFitcSuperResolution",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_fitc_super-resolution/model.yaml",
      "download_url": "https://zenodo.org/record/4290871/files/widefield_fitc_superresolution.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Widefield Super-resolution (GAN - FITC)",
      "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
          "doi": "https://doi.org/10.1038/s41592-018-0239-0"
        }
      ],
      "authors": [
        "Hongda Wang",
        "Yair Rivenson",
        "Aydogan Ozcan"
      ],
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "GAN",
        "Fluorescence microscopy",
        "deepimagej",
        "Super resolution"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_dapi_super-resolution",
      "id": "deepimagej/WidefieldDapiSuperResolution",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_dapi_super-resolution/model.yaml",
      "download_url": "https://zenodo.org/record/4290871/files/widefield_dapi_superresolution.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Widefield Super-resolution (GAN - DAPI)",
      "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
          "doi": "https://doi.org/10.1038/s41592-018-0239-0"
        }
      ],
      "authors": [
        "Hongda Wang",
        "Yair Rivenson",
        "Aydogan Ozcan"
      ],
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "GAN",
        "Fluorescence microscopy",
        "deepimagej",
        "Super resolution"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "notebook",
      "id": "deepimagej/EVsTEMsegmentationFRUNet",
      "name": "Small extracellular vesicle instance segmentation (FRU-Net)",
      "description": "Ready to use notebook for the segmentation of small extrcaellular vesicles in transmission electron microscopy (TEM) images. The notebook is optimized to use it in Google Colaboratory. It will download the original code and dataset, and make the inference connecting with Google's GPU.",
      "cite": [
        {
          "text": "G\u00f3mez-de-Mariscal, E. et al., Deep-Learning-Based Segmentation of SmallExtracellular Vesicles in Transmission Electron Microscopy Images Scientific Reports, (2019)",
          "doi": "https://doi.org/10.1038/s41598-019-49431-3"
        }
      ],
      "authors": [
        "Estibaliz G\u00f3mez-de-Mariscal",
        "Martin Ma\u0161ka, Anna Kotrbov\u00e1",
        "Vendula Posp\u00edchalov\u00e1",
        "Pavel Matula",
        "Arrate Mu\u00f1oz-Barrutia"
      ],
      "covers": [
        "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41598-019-49431-3/MediaObjects/41598_2019_49431_Fig1_HTML.png",
        "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation/frunet_sev.jpg"
      ],
      "badges": [
        {
          "label": "Open in Colab",
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "url": "https://colab.research.google.com/github/BIIG-UC3M/FRU-Net-TEM-segmentation/blob/main/FRUnet_TEM_Exosomes_sEV.ipynb"
        }
      ],
      "documentation": "https://cbia.fi.muni.cz/research/segmentation/fru-net.html",
      "tags": [
        "TEM",
        "extracellular vesicles",
        "segmentation",
        "deepimagej"
      ],
      "source": "https://raw.githubusercontent.com/BIIG-UC3M/FRU-Net-TEM-segmentation/master/FRUnet_TEM_Exosomes_sEV.ipynb",
      "links": [
        "deepimagej/FRUNet2DsEVSegmentation"
      ]
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./exampleImage.tiff",
          "./resultImage.tiff",
          "./postprocessing.txt",
          "./postprocessingWatershed.txt"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation",
      "id": "deepimagej/FRUNet2DsEVSegmentation",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation/model.yaml",
      "links": [
        "deepimagej/deepimagej",
        "deepimagej/EVsTEMsegmentationFRUNet",
        "imjoy/BioImageIO-Packager"
      ],
      "download_url": "https://zenodo.org/record/4156050/files/deepimagej_fru-net_sev_segmentation.zip",
      "format_version": "0.3.0",
      "name": "Small Extracellular Vesicle TEM Segmentation (Fully Residual U-Net)",
      "description": "DeepImageJ compatible fully residual U-Net trained to segment small extracellular vesicles in 2D TEM images",
      "cite": [
        {
          "text": "G\u00f3mez-de-Mariscal, E. et al., Deep-Learning-Based Segmentation of SmallExtracellular Vesicles in Transmission Electron Microscopy Images Scientific Reports, (2019)",
          "doi": "https://doi.org/10.1038/s41598-019-49431-3"
        }
      ],
      "authors": [
        "Estibaliz G\u00f3mez-de-Mariscal",
        "Martin Ma\u0161ka, Anna Kotrbov\u00e1",
        "Vendula Posp\u00edchalov\u00e1",
        "Pavel Matula",
        "Arrate Mu\u00f1oz-Barrutia"
      ],
      "documentation": "https://cbia.fi.muni.cz/research/segmentation/fru-net.html",
      "covers": [
        "frunet_sev.jpg"
      ],
      "tags": [
        "TEM",
        "extracellular vesicles",
        "segmentation",
        "deepimagej"
      ],
      "license": "BSD 3",
      "error": {
        "spec": {
          "run_mode": {
            "_schema": [
              "Invalid input type."
            ]
          }
        }
      }
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./post.ijm",
          "./0066.tif",
          "./lesion.csv",
          "./0066_mask.png"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/skin_lesion_classification",
      "id": "deepimagej/SkinLesionClassification",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/skin_lesion_classification/model.yaml",
      "download_url": "https://zenodo.org/record/4155785/files/SkinLesions.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej-beta"
      ],
      "format_version": "0.3.1",
      "name": "Skin lesions classification",
      "description": "CNN trained to classify the type of imaged skin lesion.",
      "authors": [
        "Carlos Garc\u00eda-L\u00f3pez-de-Haro"
      ],
      "documentation": "https://gist.github.com/esgomezm/7398a83321ae589bafadb0392c7b78ef#file-skin_lession_classification_pytorch_original-ipynb",
      "covers": [
        "cover.jpg"
      ],
      "tags": [
        "classification",
        "pytorch",
        "melanoma",
        "deepimagej-beta",
        "skin lesions",
        "deepimagej"
      ],
      "license": "BSD2",
      "git_repo": "https://gist.github.com/esgomezm/72b584887ca5ed5ed0231c47fff9aa9b#file-skin_lession_classification_pytorch_adapted-ipynb",
      "error": {
        "spec": {
          "documentation": [
            "Invalid URI: https://gist.github.com/esgomezm/7398a83321ae589bafadb0392c7b78ef#file-skin_lession_classification_pytorch_original-ipynb. We do not support fragment: file-skin_lession_classification_pytorch_original-ipynb"
          ],
          "run_mode": {
            "_schema": [
              "Invalid input type."
            ]
          },
          "cite": [
            "Missing data for required field."
          ]
        }
      }
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./Results.csv",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/defcon_density_map_estimation",
      "id": "deepimagej/SMLMDensityMapEstimationDEFCoN",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/defcon_density_map_estimation/model.yaml",
      "download_url": "https://zenodo.org/record/4608442/files/SMLM_Density%20Map_Estimation_%28DEFCoN%29.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "SMLM Density Map Estimation (DEFCoN)",
      "description": "Density Estimation by Fully Convolutional Networks (DEFCoN)   - A fluorescent spot counter for single molecule localization microscopy. DEFCoN was written by Baptiste Ottino as a Masters thesis project under the guidance of Kyle M. Douglass and Suliana Manley in the Laboratory of Experimental Biophysics.",
      "authors": [
        "Baptiste Ottino",
        "Kyle M. Douglass",
        "Suliana Manley"
      ],
      "documentation": "https://github.com/LEB-EPFL/DEFCoN-ImageJ/wiki",
      "covers": [
        "cover_image.jpg"
      ],
      "tags": [
        "smlm",
        "defcon",
        "deepimagej",
        "density estimation"
      ],
      "license": "BSD 3",
      "git_repo": "https://github.com/LEB-EPFL/DEFCoN",
      "error": {
        "spec": {
          "cite": [
            "Missing data for required field."
          ]
        }
      }
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation",
      "id": "deepimagej/UNet2DPancreaticSegmentation",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/model.yaml",
      "download_url": "https://github.com/deepimagej/models/releases/download/0.3/PancreaticCellSegmentation.U-Net.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "deepimagej/unet-pancreaticcellsegmentation",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Pancreatic Phase Contrast Cell Segmentation (U-Net)",
      "description": "DeepImageJ compatible U-Net trained to segment phase contrast microscopy images of pancreatic stem cells on a 2D polystyrene substrate.",
      "cite": [
        {
          "text": "G\u00f3mez-de-Mariscal E. et al., biorXiv 2019",
          "doi": "https://doi.org/10.1101/799270"
        },
        {
          "text": "Ulman V. et al., Nature Methods 2017",
          "doi": "https://doi.org/10.1038/nmeth.4473"
        },
        {
          "text": "Ronneberger O. et al., MICCAI 2015",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        }
      ],
      "authors": [
        "Ignacio Arganda-Carreras",
        "DeepImageJ team"
      ],
      "documentation": "https://github.com/deepimagej/models/u-net_pancreatic_segmentation/U_Net_PhC-C2DL-PSC_segmentation.ipynb",
      "git_repo": "https://github.com/deepimagej/models/u-net_pancreatic_segmentation/",
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "pancreatic stem cells",
        "segmentation",
        "deepimagej",
        "phase contrast"
      ],
      "license": "BSD-2",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tiff",
          "./resultImage.tiff"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/mu-lux_ctc_phc-c2dl-psc",
      "id": "deepimagej/MU-Lux_CTC_PhC-C2DL-PSC",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/mu-lux_ctc_phc-c2dl-psc/model.yaml",
      "download_url": "https://zenodo.org/record/4155785/files/MU-Lux_CTC_PhC-C2DL-PSC.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Pancreatic Cell Phase Contrast Segmentation (DeepWater - CTC submission)",
      "description": "The method combines deep learning with watershed segmentation. For each frame, the convolutional neural network of U-Net shape detects all cells by markers and recognizes the foreground and the background of the frame. Then, the final segmentation is generated by a Marker-Controlled Watershed transformation.",
      "cite": [
        {
          "text": "Ulman V. et al., Nature Methods 2017",
          "doi": "https://doi.org/10.1038/nmeth.447"
        },
        {
          "text": "Filip Lux and Petr Matula, arXiv 2020",
          "doi": "https://arxiv.org/abs/2004.01607"
        }
      ],
      "authors": [
        "Filip Lux, Centre for Biomedical Image Analysis, Masaryk University",
        "Petr Matula, Centre for Biomedical Image Analysis, Masaryk University"
      ],
      "git_repo": "https://gitlab.fi.muni.cz/xlux/deepwater",
      "documentation": "http://public.celltrackingchallenge.net/participants/MU-Lux-CZ.pdf",
      "covers": [
        "cover.jpg"
      ],
      "tags": [
        "deepwater",
        "watershed",
        "cell tracking challenge",
        "segmentation",
        "deepimagej",
        "phase contrast"
      ],
      "license": "MIT",
      "error": {
        "spec": {
          "run_mode": {
            "_schema": [
              "Invalid input type."
            ]
          }
        }
      }
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./postprocessing.ijm",
          "./General.jar",
          "./config.ijm",
          "./exampleImage.tif",
          "./MAX_finalMask.tif",
          "./fibroblasts_detection.csv"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/usiigaci",
      "id": "deepimagej/Usiigaci",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/usiigaci/model.yaml",
      "download_url": "https://zenodo.org/record/4155785/files/usiigaci.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej-beta",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.1",
      "name": "NIH/3T3 Fibroblast Phase Contrast Segmentation (Usiigaci-Mask R-CNN)",
      "description": "Trained model given in Usiigaci for instance segmentation of cells in a 2D substrate and phase contrast microscopy images. The model is a Mask R-CNN and the input is preprocessed to get an RGB image from the grayscale image.",
      "cite": [
        {
          "text": "Tsai, H.-F., et al., SoftwareX, 2019",
          "doi": "https://doi.org/10.1016/j.softx.2019.02.007"
        }
      ],
      "authors": [
        "Joanna Gajda",
        "Tyler F.W. Sloan",
        "Hsieh-Fu Tsai",
        "Andrei Rares",
        "Amy Q. Shen"
      ],
      "covers": [
        "Composite.tif",
        "MAX_finalMask.tif"
      ],
      "tags": [
        "usiigaci",
        "maskrcnn",
        "deepimagej-beta",
        "fibroblasts",
        "2D",
        "segmentation",
        "deepimagej",
        "phase contrast"
      ],
      "license": "MIT",
      "git_repo": "https://github.com/oist/Usiigaci",
      "error": {
        "spec": {
          "documentation": [
            "Missing data for required field."
          ],
          "outputs": {
            "0": {
              "postprocessing": [
                "Field may not be null."
              ]
            }
          }
        }
      }
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/v0.1.4/models/n2v-sem-demo",
      "id": "fiji/N2VSEMDemo",
      "source": "de.csbdresden.n2v.train.N2VPrediction",
      "links": [
        "fiji/Fiji"
      ],
      "download_url": "https://github.com/bioimage-io/fiji-bioimage-io/releases/download/v0.1.4/n2v-sem-demo.zip",
      "name": "N2V SEM Demo",
      "description": "Demo model for denoising trained on a single SEM image with Noise2Void",
      "cite": {
        "text": "Buchholz, T. et al. - Content-aware image restoration for electron microscopy. \nMethods in Cell Biology, Volume 152 p.277-289, ISSN 0091-679X (2019)",
        "doi": "https://doi.org/10.1016/bs.mch.2019.05.001"
      },
      "authors": [
        "Deborah Schmidt"
      ],
      "documentation": "README.md",
      "covers": [
        "thumbnail.png"
      ],
      "tags": [
        "denoising",
        "fiji",
        "unet2d",
        "n2v"
      ],
      "license": "BSD 3",
      "format_version": "0.1.0",
      "error": {
        "spec": {
          "timestamp": [
            "Missing data for required field."
          ],
          "inputs": {
            "0": {
              "_schema": [
                "Input shape step has to be zero in the batch dimension (the batch dimension can always be increased, but `step` should specify how to increase the minimal shape to find the largest single batch shape)"
              ]
            }
          },
          "test_outputs": [
            "Missing data for required field."
          ],
          "format_version": [
            "Must be one of: 0.3.0, 0.3.1."
          ],
          "test_inputs": [
            "Missing data for required field."
          ],
          "weights": [
            "Missing data for required field."
          ],
          "cite": [
            "Invalid type."
          ],
          "test_output": [
            "Unknown field."
          ],
          "prediction": [
            "Unknown field."
          ],
          "test_input": [
            "Unknown field."
          ],
          "training": [
            "Unknown field."
          ]
        }
      }
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/mt3_virtual_staining",
      "id": "deepimagej/Mt3VirtualStaining",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/mt3_virtual_staining/model.yaml",
      "download_url": "https://zenodo.org/record/4290839/files/mt3_virtual_staining.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Masson\u2019s Trichrome Virtual Staining (GAN)",
      "description": "A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Biomedical Engineering, 2019",
          "doi": "https://doi.org/10.1038/s41551-019-0362-y"
        }
      ],
      "authors": [
        "Yair Rivenson",
        "Hongda Wang",
        "Aydogan Ozcan"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "GAN",
        "Virtual staining",
        "deepimagej",
        "histology"
      ],
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/jones_virtual_staining",
      "id": "deepimagej/JonesVirtualStaining",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/jones_virtual_staining/model.yaml",
      "download_url": "https://zenodo.org/record/4290839/files/jones_virtual_staining.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Jones Virtual Staining (GAN)",
      "description": "A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Biomedical Engineering, 2019",
          "doi": "https://doi.org/10.1038/s41551-019-0362-y"
        }
      ],
      "authors": [
        "Yair Rivenson",
        "Hongda Wang",
        "Aydogan Ozcan"
      ],
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "GAN",
        "Virtual staining",
        "deepimagej",
        "histology"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tiff",
          "./Results.csv",
          "./resultImage.tiff"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_hela_segmentation",
      "id": "deepimagej/UNet2DHeLaSegmentation",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_hela_segmentation/model.yaml",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "download_url": "https://zenodo.org/record/4155785/files/deepimagej_u-net_hela_segmentation.zip",
      "format_version": "0.3.0",
      "name": "HeLa DIC Cell Segmentation (U-Net)",
      "description": "DeepImageJ compatible U-Net trained to segment Hela cells in 2D phase contrast microscopy images",
      "cite": [
        {
          "text": "Ronneberger O. et al., MICCAI 2015",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        },
        {
          "text": "Ulman V. et al., Nature Methods 2017",
          "doi": "https://doi.org/10.1038/nmeth.4473"
        }
      ],
      "authors": [
        "Jo\u00e3o Soares Lopes"
      ],
      "documentation": "https://deepimagej.github.io/deepimagej/models_documentation.html",
      "covers": [
        "unet_hela_seg.jpg"
      ],
      "tags": [
        "segmentation",
        "hela cells",
        "deepimagej",
        "phase contrast"
      ],
      "license": "BSD-2",
      "git_repo": "https://github.com/deepimagej/python4deepimagej/tree/master/unet",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tiff",
          "./Results.csv",
          "./resultImage.tiff"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_glioblastoma_segmentation",
      "id": "deepimagej/UNet2DGlioblastomaSegmentation",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_glioblastoma_segmentation/model.yaml",
      "download_url": "https://zenodo.org/record/4155785/files/deepimagej_u-net_glioblastoma_segmentation.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Glioblastoma Phase Contrast Cell Segmentation (U-Net)",
      "description": "DeepImageJ compatible U-Net trained to segment 2D phase contrast microscopy images of glioblastoma-astrocytoma U373 cells on a polyacrylamide substrate.",
      "cite": [
        {
          "text": "Ronneberger O. et al., MICCAI 2015",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        },
        {
          "text": "Ulman V. et al., Nature Methods 2017",
          "doi": "https://doi.org/10.1038/nmeth.4473"
        }
      ],
      "authors": [
        "Jo\u00e3o Soares Lopes"
      ],
      "documentation": "README.md",
      "covers": [
        "cover_image.jpg"
      ],
      "tags": [
        "phase contrast",
        "segmentation",
        "deepimagej",
        "glioblastoma cells"
      ],
      "license": "BSD-2",
      "git_repo": "https://github.com/deepimagej/python4deepimagej/tree/master/unet",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./postprocessing_LocalMaximaSMLM.ijm",
          "./exampleImage.tiff",
          "./Localizations_resultImage_max.csv",
          "./resultImage.tiff",
          "./DeepSTORM4stacksThunderSTORM.ijm",
          "./postprocessing_AveragedMaximaSMLM.ijm"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/deepstorm_zerocostdl4mic",
      "id": "deepimagej/DeepSTORMZeroCostDL4Mic",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/deepstorm_zerocostdl4mic/model.yaml",
      "download_url": "https://zenodo.org/record/4155785/files/DeepImageJ_DeepSTORM_ZeroCostDL4Mic.zip",
      "links": [
        "zero/Notebook_Deep-STORM_2D_ZeroCostDL4Mic_DeepImageJ",
        "zero/Dataset_Deep-STORM_ZeroCostDL4Mic",
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Glial Cell SMLM (DeepSTORM - ZeroCostDL4Mic)",
      "description": "A trained Deep-STORM model for image reconstruction from high-density single-molecule localization microscopy (SMLM).",
      "cite": [
        {
          "text": "Nehme E. et al., Optica 2018",
          "doi": "https://doi.org/10.1364/OPTICA.5.000458"
        },
        {
          "text": "Lucas von Chamier et al. biorXiv 2020",
          "doi": "https://doi.org/10.1101/2020.03.20.000133"
        },
        {
          "text": "G\u00f3mez de Mariscal et al. bioRxiv 2019",
          "doi": "https://doi.org/10.1101/799270"
        }
      ],
      "authors": [
        "ZeroCostDL4Mic team",
        "DeepImageJ team"
      ],
      "git_repo": "https://github.com/HenriquesLab/ZeroCostDL4Mic",
      "documentation": "https://deepimagej.github.io/deepimagej",
      "covers": [
        "input.png",
        "zoom.png"
      ],
      "tags": [
        "zerocostdl4mic",
        "super-resolution",
        "image reconstruction",
        "SMLM",
        "deepimagej"
      ],
      "license": "MIT",
      "error": {
        "spec": {
          "test_outputs": [
            "Missing data for required field."
          ],
          "run_mode": {
            "_schema": [
              "Invalid input type."
            ]
          },
          "test_inputs": [
            "Missing data for required field."
          ]
        }
      }
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/3du-net_zerocostdl4mic",
      "id": "deepimagej/3DUNetZeroCostDL4Mic",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/3du-net_zerocostdl4mic/model.yaml",
      "download_url": "https://zenodo.org/record/4155785/files/3DUNet_ZeroCostDL4Mic.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej-beta",
        "zero/Notebook_U-Net_3D_ZeroCostDL4Mic",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "3D U-Net - ZeroCostDL4Mic",
      "description": "3D U-Net trained using ZeroCostDL4Mic notebooks to segment mitochondria in Transmission Electron Microscopy (TEM) data.",
      "cite": [
        {
          "text": "Lucas von Chamier et al. bioRxiv 2020",
          "doi": "https://doi.org/10.1101/2020.03.20.000133"
        },
        {
          "text": "\u00d6zg\u00fcn \u00c7i\u00e7ek et al., MICCAI 2016",
          "doi": "https://doi.org/10.1007/978-3-319-46723-8_49"
        }
      ],
      "authors": [
        "DeepImageJ team"
      ],
      "documentation": "https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki",
      "covers": [
        "exampleImage.gif"
      ],
      "tags": [
        "TEM",
        "deepimagej",
        "ZeroCostDL4Mic",
        "deepimagej-beta",
        "segmentation",
        "mitochondria",
        "3DUNet"
      ],
      "license": "MIT",
      "git_repo": "https://github.com/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb",
      "error": {
        "spec": {
          "run_mode": {
            "_schema": [
              "Invalid input type."
            ]
          }
        }
      }
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./postprocessing.ijm",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/2du-net_zerocostdl4mic",
      "id": "deepimagej/2DUNetZeroCostDL4Mic",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/2du-net_zerocostdl4mic/model.yaml",
      "download_url": "https://zenodo.org/record/4155785/files/DeepImageJ_2D%20UNet_ZeroCostDL4Mic.zip",
      "links": [
        "zero/Notebook_U-Net_2D_ZeroCostDL4Mic_DeepImageJ",
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "2D UNet - ZeroCostDL4Mic",
      "description": "2D U-Net trained for binary segmentation using the EM images of neuronal membranes and segmentation masks from the ISBI segmentation challenge 2012.",
      "cite": [
        {
          "text": "Ronneberger O. et al., MICCAI 2015",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        },
        {
          "text": "Lucas von Chamier et al. bioRxiv 2020",
          "doi": "https://doi.org/10.1101/2020.03.20.000133"
        },
        {
          "text": "G\u00f3mez de Mariscal et al. bioRxiv 2019",
          "doi": "https://doi.org/10.1101/799270"
        }
      ],
      "authors": [
        "ZeroCostDL4Mic team",
        "DeepImageJ team"
      ],
      "git_repo": "https://github.com/HenriquesLab/ZeroCostDL4Mic",
      "documentation": "https://deepimagej.github.io/deepimagej",
      "covers": [
        "cover.png"
      ],
      "tags": [
        "segmentation",
        "unet",
        "zerocostdl4mic",
        "deepimagej"
      ],
      "license": "MIT",
      "error": {}
    },
    {
      "type": "notebook",
      "id": "deepimagej/unet-pancreaticcellsegmentation",
      "name": "2D U-Net for binary segmentation",
      "description": "Easy example to define a 2D U-Net for segmentation with Keras and import it into DeepImageJ format",
      "cite": [
        {
          "text": "Falk, T., Mai, D., Bensch, R. et al. U-Net: deep learning for cell counting, detection, and morphometry. Nat Methods 16, 67\u201370 (2019).",
          "doi": "https://doi.org/10.1038/s41592-018-0261-2"
        }
      ],
      "authors": [
        "Ignacio Arganda-Carreras",
        "DeepImageJ team"
      ],
      "covers": [
        "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/notebook_intro.png",
        "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/usecase.png"
      ],
      "badges": [
        {
          "label": "Open in Colab",
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "url": "https://colab.research.google.com/github/deepimagej/models/blob/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb"
        }
      ],
      "documentation": "https://github.com/miura/NEUBIAS_AnalystSchool2020/tree/master/Ignacio",
      "tags": [
        "unet",
        "segmentation",
        "deepimagej"
      ],
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb",
      "links": [
        "deepimagej/UNet2DPancreaticSegmentation"
      ]
    }
  ]
}