{
  "id": "bioimage.io",
  "name": "BioImage.IO",
  "tags": [],
  "logo": "\ud83e\udd92",
  "icon": "\ud83e\udd92",
  "splash_title": "Bioimage Model Zoo",
  "splash_subtitle": "Advanced AI models in one-click",
  "splash_feature_list": [
    "Integrate with Fiji, Ilastik, ImJoy",
    "Try model instantly with BioEngine",
    "Contribute your models via Github",
    "Link models to datasets and applications"
  ],
  "explore_button_text": "Start Exploring",
  "background_image": "static/img/zoo-background.svg",
  "resource_types": [
    "model",
    "application",
    "notebook",
    "dataset"
  ],
  "default_type": "model",
  "url_root": "https://raw.githubusercontent.com/bioimage-io/bioimage-io-models/master",
  "collections": [
    {
      "id": "deepimagej",
      "name": "deepImageJ",
      "tags": [
        "deepimagej"
      ],
      "logo": "https://raw.githubusercontent.com/deepimagej/models/master/logos/logo.png",
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "splash_title": "deepImageJ",
      "splash_subtitle": "A user-friendly plugin to run deep learning models in ImageJ",
      "splash_feature_list": null,
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "model",
        "notebook"
      ],
      "url_root": "https://raw.githubusercontent.com/deepimagej/models/master"
    },
    {
      "id": "zero",
      "name": "ZeroCostDL4Mic",
      "version": "0.1.0",
      "tags": [
        "ZeroCostDL4Mic"
      ],
      "logo": "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/colab_logo.png",
      "icon": "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/colab_logo.png",
      "splash_title": "ZeroCostDL4Mic",
      "splash_subtitle": "A Google Colab based no-cost toolbox to explore Deep-Learning in Microscopy",
      "splash_feature_list": [],
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "model",
        "notebook",
        "dataset"
      ],
      "url_root": "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master"
    },
    {
      "id": "fiji",
      "name": "Fiji",
      "tags": [
        "fiji"
      ],
      "logo": "https://fiji.sc/site/logo.png",
      "icon": "https://fiji.sc/site/logo.png",
      "splash_title": "Fiji",
      "splash_subtitle": "Fiji is just ImageJ",
      "splash_feature_list": [],
      "explore_button_text": "Start Exploring",
      "background_image": "static/img/zoo-background.svg",
      "resource_types": [
        "model",
        "notebook"
      ],
      "url_root": "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master"
    }
  ],
  "resources": [
    {
      "id": "Notebook Preview",
      "type": "application",
      "source": "https://raw.githubusercontent.com/bioimage-io/nbpreview/master/notebook-preview.imjoy.html",
      "name": "Notebook Preview",
      "version": "0.1.0",
      "api_version": "0.2.3",
      "description": "Previewing Jupyter notebook without a Jupyter server",
      "tags": [
        "notebook",
        "imjoy",
        "jupyter"
      ],
      "covers": [],
      "badges": [],
      "authors": []
    },
    {
      "id": "Kaibu",
      "type": "application",
      "source": "https://raw.githubusercontent.com/imjoy-team/kaibu/master/Kaibu.imjoy.html",
      "name": "Kaibu",
      "version": "0.1.12",
      "api_version": "0.2.3",
      "description": "Kaibu--a web application for visualizing and annotating multi-dimensional images",
      "tags": [],
      "covers": [
        "https://raw.githubusercontent.com/imjoy-team/kaibu/master/public/static/img/kaibu-screenshot-1.png"
      ],
      "badges": [
        {
          "icon": "https://imjoy.io/static/badge/launch-imjoy-badge.svg",
          "label": "Launch ImJoy",
          "url": "https://imjoy.io/#/app?plugin=https://kaibu.org/#/app"
        },
        {
          "icon": "https://mybinder.org/badge_logo.svg",
          "label": "Launch Binder",
          "url": "https://mybinder.org/v2/gist/oeway/690c2e62311223ae93e644d542eb8949/master?filepath=Kaibu-jupyter-tutorial.ipynb"
        }
      ],
      "authors": [
        "ImJoy-Team"
      ]
    },
    {
      "id": "Ilastik",
      "type": "application",
      "source": "https://raw.githubusercontent.com/bioimage-io/bioimage-io-models/master/src/Ilastik-app.imjoy.html",
      "icon": "https://raw.githubusercontent.com/bioimage-io/models/master/assets/icons/Ilastik-icon.png",
      "name": "Ilastik",
      "version": "0.1.0",
      "api_version": "0.1.7",
      "description": "Ilastik Model Preview for BioImage.io",
      "requirements": [
        "https://static.imjoy.io/spectre.css/spectre.min.css",
        "https://static.imjoy.io/spectre.css/spectre-exp.min.css",
        "https://static.imjoy.io/spectre.css/spectre-icons.min.css"
      ],
      "dependencies": [
        "https://gist.githubusercontent.com/oeway/2d4b5899424a14d8e90ad908d4cec364/raw/TiktorchModelLoader.imjoy.html",
        "https://gist.githubusercontent.com/oeway/f09955746ec01a20053793aba83c3545/raw/CompareImages.imjoy.html"
      ],
      "env": "",
      "tags": [],
      "covers": [],
      "badges": [],
      "authors": []
    },
    {
      "id": "HPA-Classification",
      "type": "application",
      "source": "https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/HPA-Classification.imjoy.html",
      "icon": "https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/apps/hpa-logo.gif",
      "name": "HPA-Classification",
      "version": "0.2.1",
      "api_version": "0.1.7",
      "description": "ShuffleNetV2 for HPA.",
      "requirements": [
        "https://cdnjs.cloudflare.com/ajax/libs/js-yaml/3.13.1/js-yaml.min.js",
        "https://cdn.jsdelivr.net/npm/apexcharts",
        "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs",
        "https://cdn.jsdelivr.net/npm/simpleheat@0.4.0/simpleheat.min.js",
        "https://cdn.jsdelivr.net/gh/photopea/UTIF.js@4f1b10cb09e244cfd4f9631245d2231537148be7/UTIF.js"
      ],
      "dependencies": [
        "https://raw.githubusercontent.com/imjoy-team/example-plugins/master/imjoy-plugins/HPA-Image-Selection.imjoy.html"
      ],
      "env": null,
      "tags": [],
      "covers": [
        "https://imjoy-team.github.io/imjoy-plugins/hpa-classification/hpa-classification-cover.gif"
      ],
      "badges": [],
      "authors": []
    },
    {
      "id": "Fiji",
      "name": "Fiji",
      "description": "Fiji is an image processing package \u2014 a \"batteries-included\" distribution of ImageJ, bundling many plugins which facilitate scientific image analysis.",
      "source": "https://fiji.sc/",
      "cite": {
        "text": "Schindelin, J., Arganda-Carreras, I., Frise, E. et al. Fiji: an open-source platform for biological-image analysis. Nat Methods 9, 676\u2013682 (2012).",
        "doi": "https://doi.org/10.1038/nmeth.2019"
      },
      "authors": [
        "Fiji community"
      ],
      "icon": "https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/master/Fiji-icon.png",
      "documentation": "https://fiji.sc/",
      "git_repo": "https://github.com/fiji/fiji",
      "tags": [
        "fiji"
      ],
      "type": "application"
    },
    {
      "type": "notebook",
      "root_url": "https://gist.githubusercontent.com/oeway/582856630a0aed4d4d221e54df1b3ece/raw",
      "id": "vitessce-image-viewer",
      "source": "https://gist.githubusercontent.com/oeway/ebedc17c9ab1f6aa5eee181679d85b5f/raw/vitessce-image-viewer-imjoy-demo.ipynb",
      "links": [
        "Notebook Preview"
      ],
      "name": "Vitessce Image Viewer",
      "description": "Use vitessce-image-viewer in Jupyter notebooks with ImJoy Jupyter Extension",
      "cite": null,
      "authors": [
        "Wei OUYANG"
      ],
      "badges": [
        {
          "label": "Launch Binder",
          "icon": "https://mybinder.org/badge_logo.svg",
          "url": "https://mybinder.org/v2/gist/oeway/ebedc17c9ab1f6aa5eee181679d85b5f/master?filepath=vitessce-image-viewer-imjoy-demo.ipynb"
        },
        {
          "label": "Powered by ImJoy",
          "url": "https://imjoy.io",
          "icon": "https://imjoy.io/static/badge/powered-by-imjoy-badge.svg"
        }
      ],
      "tags": [
        "visualization",
        "imjoy"
      ]
    },
    {
      "type": "notebook",
      "root_url": "https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Colab_notebooks",
      "id": "unet-2d",
      "name": "U-net (2D)",
      "description": "U-Net for segmentation",
      "cite": {
        "text": "Falk, T., Mai, D., Bensch, R. et al. U-Net: deep learning for cell counting, detection, and morphometry. Nat Methods 16, 67\u201370 (2019).",
        "doi": "https://doi.org/10.1038/s41592-018-0261-2"
      },
      "authors": [
        "ZeroCostDL4Mic Team"
      ],
      "covers": [
        "https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/wiki%20unet.png"
      ],
      "badges": [
        {
          "label": "Open in Colab",
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "url": "https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-net_2D_ZeroCostDL4Mic.ipynb"
        }
      ],
      "documentation": null,
      "tags": [
        "ZeroCostDL4Mic",
        "UNet",
        "segmentation"
      ],
      "source": "https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Colab_notebooks/U-net_2D_ZeroCostDL4Mic.ipynb"
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation",
      "id": "UNet2DPancreaticSegmentation",
      "source": "https://github.com/deepimagej/models/u-net_pancreatic_segmentation/U_Net_PhC-C2DL-PSC_segmentation.ipynb",
      "links": [
        "unet-pancreaticcellsegmentation"
      ],
      "name": "U-Net Pancreatic Cell Segmentation",
      "description": "DeepImageJ compatible U-Net trained to segment phase contrast microscopy images of pancreatic stem cells on a 2D polystyrene substrate.",
      "cite": {
        "text": "G\u00f3mez-de-Mariscal E. et al., biorXiv 2019; Ulman V. et al., Nature Methods 2017; Ronneberger O. et al., MICCAI 2015",
        "doi": null
      },
      "authors": [
        "DeepImageJ",
        "Ignacio Arganda-Carreras"
      ],
      "documentation": "https://deepimagej.github.io/deepimagej/models_documentation.html",
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "segmentation",
        "deepimagej",
        "pancreatic stem cells",
        "phase contrast"
      ],
      "license": null,
      "format_version": null,
      "model": {
        "source": "./saved_model.pb",
        "sha256": null,
        "v1": {
          "source": "./variables",
          "sha256": null
        }
      }
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_hela_segmentation",
      "id": "UNet2DHelaSegmentation",
      "source": "https://github.com/deepimagej/python4deepimagej/tree/master/unet",
      "name": "U-Net Hela Cell Segmentation",
      "description": "DeepImageJ compatible U-Net trained to segment Hela cells in 2D phase contrast microscopy images",
      "cite": {
        "text": "Biomedical Imaging Group, School of Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland",
        "doi": null
      },
      "authors": [
        "Jo\u00e3o Soares Lopes"
      ],
      "documentation": "https://deepimagej.github.io/deepimagej/models_documentation.html",
      "covers": null,
      "tags": [
        "deepimagej",
        "hela cells",
        "segmentation",
        "phase contrast"
      ],
      "license": null,
      "format_version": null,
      "model": {
        "source": "./saved_model.pb",
        "sha256": "601830ca4462cc7b6d1047541bd2e6de105dbc92d6da42d840700eaf65aef0e7",
        "v1": {
          "source": "./variables",
          "sha256": null
        }
      }
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/subeeshvasu/hbp-DL-seg-codes/0.1.2",
      "id": "UNetDA",
      "source": "src.utils.get_unet",
      "links": [
        "Ilastik"
      ],
      "download_url": "https://github.com/subeeshvasu/hbp-DL-seg-codes/releases/download/0.1.2/UNetDA.model.zip",
      "name": "U-Net DA (Domain Adaptation)",
      "description": "U-Net trained on brain vasculature segmentation data from Ludovico Silvestri's European Laboratory for Non-linear Spectroscopy (LENS). U-Net is used as the segmentation network that takes up the inputs from source and target domain, and generate the respective segmentation results at the output. To train the network, cross entropy loss between the prediction and ground truth labels is used for the source data. For the target data, image reconstrcution constraints are enforced on the segmentation outputs. Furthermore, source domain images are translated into the target domain using an adverserial paradigm, to generate auxiliary labelled data for the target domain. The labelled data thus generated are used to establish a supervised loss in the target domain.",
      "cite": [
        {
          "text": "Ronneberger, Olaf et al. U-net: Convolutional networks for biomedical image segmentation. MICCAI 2015.",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        }
      ],
      "authors": [
        "Vasu Subeesh"
      ],
      "documentation": "documentation/TransferLearningBasedSegmentationWorkflow.md",
      "tags": [
        "vasculature",
        "hbp",
        "unet2d",
        "brain",
        "sga2",
        "pytorch"
      ],
      "license": "MIT",
      "format_version": "0.1.0",
      "covers": [
        "documentation/covers/UNetCover.png"
      ]
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/subeeshvasu/hbp-DL-seg-codes/0.1.2",
      "id": "2sUNetDA",
      "source": "src.utils.get_2sunet",
      "links": [
        "Ilastik"
      ],
      "download_url": "https://github.com/subeeshvasu/hbp-DL-seg-codes/releases/download/0.1.2/2sUNetDA.model.zip",
      "name": "Two Steam U-Net DA",
      "description": "Two Steam U-Net trained on brain vasculature segmentation data from Ludovico Silvestri's European Laboratory for Non-linear Spectroscopy (LENS). Two Steam U-Net is used as the segmentation network that takes up the inputs from source and target domain, and generate the respective segmentation results at the output. Two Steam U-Net uses differet encoders to process inputs from source and target, and use a common decoder to generate the respective segmentation outputs. To train the network, cross entropy loss between the prediction and ground truth labels is used for the source data. For the target data, image reconstrcution constraints are enforced on the segmentation outputs. Furthermore, source domain images are translated into the target domain using an adverserial paradigm, to generate auxiliary labelled data for the target domain. The labelled data thus generated are used to establish a supervised loss in the target domain.",
      "cite": [
        {
          "text": "Roger Bermudez et al. A domain-adaptive two-stream U-Net for electron microscopy image segmentation. ISBI 2018.",
          "doi": "https://doi.org/10.1109/ISBI.2018.8363602"
        }
      ],
      "authors": [
        "Roger Bermudez, Vasu Subeesh"
      ],
      "documentation": "documentation/TransferLearningBasedSegmentationWorkflow.md",
      "tags": [
        "vasculature",
        "hbp",
        "unet2d",
        "brain",
        "sga2",
        "pytorch"
      ],
      "license": "MIT",
      "format_version": "0.1.0",
      "covers": [
        "documentation/covers/2sUNetCover.png"
      ]
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/bioimage-io/fiji-bioimage-io/v0.1.4/models/n2v-sem-demo",
      "id": "N2VSEMDemo",
      "source": "de.csbdresden.n2v.train.N2VPrediction",
      "links": [
        "Fiji"
      ],
      "download_url": "https://github.com/bioimage-io/fiji-bioimage-io/releases/download/v0.1.4/n2v-sem-demo.zip",
      "name": "N2V SEM Demo",
      "description": "Demo model for denoising trained on a single SEM image with Noise2Void",
      "cite": {
        "text": "Buchholz, T. et al. - Content-aware image restoration for electron microscopy. \nMethods in Cell Biology, Volume 152 p.277-289, ISSN 0091-679X (2019)",
        "doi": "https://doi.org/10.1016/bs.mch.2019.05.001"
      },
      "authors": [
        "Deborah Schmidt"
      ],
      "documentation": "README.md",
      "covers": [
        "thumbnail.png"
      ],
      "tags": [
        "unet2d",
        "fiji",
        "denoising",
        "n2v"
      ],
      "license": "BSD 3",
      "format_version": "0.1.0"
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/bioimage-io/tfjs-bioimage-io/master/models/HPAShuffleNetV2",
      "id": "HPAShuffleNetV2",
      "source": "https://raw.githubusercontent.com/oeway/Anet-Model-Zoo/master/4_hpa_shufflenet_v2/model.json",
      "links": [
        "HPA-Classification"
      ],
      "name": "HPA ShuffleNetV2",
      "description": "A light-weight model for HPA image classification competition",
      "cite": null,
      "authors": [
        "Moshe Livne",
        "Wei OUYANG"
      ],
      "documentation": "HPAShuffleNetV2.md",
      "tags": [
        "shufflenet",
        "imjoy",
        "classification",
        "tensorflow.js"
      ],
      "git_repo": "https://github.com/CellProfiling/HPA-Special-Prize",
      "badges": [
        {
          "url": "https://imjoy.io",
          "icon": "https://imjoy.io/static/badge/powered-by-imjoy-badge.svg",
          "label": "Powered by ImJoy"
        }
      ],
      "license": "Apache 2.0",
      "format_version": "0.1.0",
      "covers": [
        "https://imjoy-team.github.io/imjoy-plugins/hpa-classification/hpa-classification-cover.gif"
      ]
    },
    {
      "type": "model",
      "attachments": {
        "weights": [
          {
            "id": "v1",
            "name": "version 1",
            "description": "weights trained for segmenting small extracellular vesicles",
            "source": "./variables",
            "sha256": null
          }
        ]
      },
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation",
      "id": "FRUNet2DsEVSegmentation",
      "source": "https://cbia.fi.muni.cz/research/segmentation/fru-net.html",
      "download_url": "https://github.com/deepimagej/models/releases/download/0.1/fru-net_sev_segmentation.zip",
      "name": "Fully Residual U-Net - TEM",
      "description": "DeepImageJ compatible fully residual U-Net trained to segment small extracellular vesicles in 2D TEM images",
      "cite": {
        "text": "G\u00f3mez-de-Mariscal, E. et al., Deep-Learning-Based Segmentation of SmallExtracellular Vesicles in Transmission Electron Microscopy Images \nScientific Reports, (2019)",
        "doi": "https://doi.org/10.1038/s41598-019-49431-3"
      },
      "authors": [
        "Estibaliz G\u00f3mez-de-Mariscal",
        "Martin Ma\u0161ka",
        "Anna Kotrbov\u00e1",
        "Vendula Posp\u00edchalov\u00e1",
        "Pavel Matula and Arrate Mu\u00f1oz-Barrutia"
      ],
      "documentation": "https://cbia.fi.muni.cz/research/segmentation/fru-net.html",
      "covers": [
        "frunet_sev.jpg"
      ],
      "tags": [
        "TEM",
        "deepimagej",
        "extracellular vesicles",
        "segmentation"
      ],
      "license": "BSD 3",
      "format_version": "0.2.0",
      "model": {
        "source": "./saved_model.pb",
        "sha256": "9ccb79070f30813e7447342e3ab7f4107a314a1414c1541c79134ef950ac4a7f"
      }
    },
    {
      "type": "dataset",
      "attachments": {
        "files": [
          "https://gist.githubusercontent.com/manzt/d16dbac0ea3adc3c7b9b61f54fa1f78d/raw/95854058512862accb0182d4a02f86a55ad19139/"
        ]
      },
      "root_url": "https://gist.githubusercontent.com/oeway/3dcbd79cd29da42be13a7e3bc0f9ca12/raw",
      "id": "dummy_zarr",
      "source": "https://gist.githubusercontent.com/oeway/3dcbd79cd29da42be13a7e3bc0f9ca12/raw/dummy_zarr.dataset.yaml",
      "name": "Dummy Zarr",
      "description": "A dummy zarr dataset",
      "cite": null,
      "authors": [
        "NO ONE"
      ],
      "documentation": null,
      "tags": [
        "zarr"
      ]
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/platybrowser/platybrowser/3711f1c26e5db8c38c3faff4cccb3110560e3c67/segmentation/cells/UNet3DPlatyCellProbs.model",
      "id": "UNet3DPlatyCellProbs",
      "source": "mmpb.segmentation.network.models.UNetAnisotropic",
      "links": [
        "Ilastik"
      ],
      "download_url": "https://github.com/platybrowser/platybrowser/releases/download/1.0.0/UNet3DPlatyCellProbs.model.zip",
      "name": "3D UNet Platynereis Cell Segmentation (Probabilities)",
      "description": "A 3d U-Net trained to predict the cell boundaries in a EM volume of a 6 day old Platynereis.",
      "cite": [
        {
          "text": "Vergara, Hernando M. et al. Whole-body integration of gene expression and single-cell morphology. BioRxiv 2020.\"",
          "doi": "https://doi.org/10.1101/2020.02.26.961037"
        }
      ],
      "authors": [
        "Constantin Pape;@bioimage-io"
      ],
      "documentation": "README.md",
      "tags": [
        "EM",
        "unet3d",
        "segmentation",
        "cell membrane",
        "platynereis",
        "pytorch"
      ],
      "license": "MIT",
      "format_version": "0.1.0",
      "covers": [
        "ilastik_raw.png",
        "ilastik_pred.png"
      ]
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/wolny/pytorch-3dunet/37f186c80f4d64b1dab5d165d8c2aae15b5aede1/bioimage-io/UNet3DArabidopsisOvules.model",
      "id": "UNet3DArabidopsisOvules",
      "source": "pytorch3dunet.unet3d.model.UNet3D",
      "links": [
        "Ilastik"
      ],
      "download_url": "https://github.com/wolny/pytorch-3dunet/releases/download/1.2.6/UNet3DArabidopsisOvules.model.zip",
      "name": "3D UNet Arabidopsis Ovules",
      "description": "A 3d U-Net trained to predict the cell boundaries in confocal stacks of Arabidopsis ovules. Voxel size: (0.235, 0.150, 0.150) microns ZYX",
      "cite": [
        {
          "text": "Wolny, Adrian et al. Accurate and Versatile 3D Segmentation of Plant Tissues at Cellular Resolution. BioRxiv 2020.",
          "doi": "https://doi.org/10.1101/2020.01.17.910562"
        }
      ],
      "authors": [
        "Adrian Wolny;@bioimage-io"
      ],
      "documentation": "README.md",
      "tags": [
        "unet3d",
        "arabidopsis",
        "segmentation",
        "plant tissue",
        "ovuls",
        "cell membrane",
        "pytorch"
      ],
      "license": "MIT",
      "format_version": "0.1.0",
      "covers": [
        "ilastik_4.png",
        "ilastik_5.png",
        "ilastik_6.png",
        "ilastik_7.png",
        "ilastik_8.png"
      ]
    },
    {
      "type": "dataset",
      "root_url": "https://github.com/zhixuhao/unet/tree/master/data",
      "id": "ZeroCostDL4Mic_2D_Unet_dataset",
      "name": "2D Unet Segmentation Dataset",
      "description": "Segmentation Dataset from ISBI2012 segmentation challenge showing EM images of neuronal membranes and the associated segmentation maps",
      "cite": "Ignacio Arganda-Carreras, Srinivas C. Turaga, Daniel R. Berger, Dan Ciresan, Alessandro Giusti, Luca M. Gambardella, J\u00fcrgen Schmidhuber, Dmtry Laptev, Sarversh Dwivedi, Joachim M. Buhmann, Ting Liu, Mojtaba Seyedhosseini, Tolga Tasdizen, Lee Kamentsky, Radim Burget, Vaclav Uher, Xiao Tan, Chanming Sun, Tuan D. Pham, Eran Bas, Mustafa G. Uzunbas, Albert Cardona, Johannes Schindelin, and H. Sebastian Seung. Crowdsourcing the creation of image segmentation algorithms for connectomics. Frontiers in Neuroanatomy, vol. 9, no. 142, 2015.",
      "authors": [],
      "documentation": null,
      "tags": [
        "ZeroCostDL4Mic",
        "UNet",
        "segmentation"
      ],
      "source": "https://github.com/zhixuhao/unet/tree/master/data/membrane"
    },
    {
      "type": "model",
      "root_url": "https://raw.githubusercontent.com/bioimage-io/pytorch-bioimage-io/v0.1.1/specs/models/unet2d/nuclei_broad",
      "id": "UNet2DNucleiBroad",
      "source": "pybio.torch.models.unet.UNet2d",
      "links": [
        "Ilastik"
      ],
      "download_url": "https://github.com/bioimage-io/pytorch-bioimage-io/releases/download/v0.1.1/UNet2DNucleiBroad.model.zip",
      "name": "2D UNet Nuclei Broad",
      "description": "A 2d U-Net pretrained on broad nucleus dataset.",
      "cite": [
        {
          "text": "Ronneberger, Olaf et al. U-net: Convolutional networks for biomedical image segmentation. MICCAI 2015.",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        }
      ],
      "authors": [
        "Constantin Pape;@bioimage-io",
        "Fynn Beuttenm\u00fcller"
      ],
      "documentation": "UNet2DNucleiBroad.md",
      "tags": [
        "unet2d",
        "nucleus-segmentation",
        "pytorch"
      ],
      "license": "MIT",
      "format_version": "0.1.0",
      "covers": [
        "cover0.png"
      ]
    },
    {
      "type": "notebook",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation",
      "id": "unet-pancreaticcellsegmentation",
      "name": "2D U-Net for binary segmentation",
      "description": "Easy example to define a 2D U-Net for segmentation with Keras and import it into DeepImageJ format",
      "cite": {
        "text": "Falk, T., Mai, D., Bensch, R. et al. U-Net: deep learning for cell counting, detection, and morphometry. Nat Methods 16, 67\u201370 (2019).",
        "doi": "https://doi.org/10.1038/s41592-018-0261-2"
      },
      "authors": [
        "Ignacio Arganda-Carreras and DeepImageJ"
      ],
      "covers": [
        "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/notebook_intro.png",
        "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/usecase.png"
      ],
      "badges": [
        {
          "label": "Open in Colab",
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "url": "https://colab.research.google.com/github/deepimagej/models/blob/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb"
        }
      ],
      "documentation": "https://github.com/miura/NEUBIAS_AnalystSchool2020/tree/master/Ignacio",
      "tags": [
        "deepimagej",
        "UNet",
        "DeepImageJ",
        "segmentation"
      ],
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb"
    }
  ]
}